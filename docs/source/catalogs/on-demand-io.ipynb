{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. currentmodule:: nbodykit.base.catalog\n",
    "\n",
    ".. _on-demand-io:\n",
    "\n",
    "On Demand IO via :mod:`dask.array`\n",
    "==================================\n",
    "\n",
    "nbodykit uses the `dask <http://dask.pydata.org>`_ package to store the columns\n",
    "in :class:`CatalogSource` objects. The :mod:`dask` package implements\n",
    "a :class:`dask.array.Array` object that mimics that interface of the more\n",
    "familiar numpy array. In this section, we describe what exactly a dask array\n",
    "is and how it is used in nbodykit.\n",
    "\n",
    ".. _what-is-dask-array:\n",
    "\n",
    "What is a dask array?\n",
    "---------------------\n",
    "\n",
    "In nbodykit, the dask array object is a data container that behaves nearly\n",
    "identical to a numpy array, except for one key difference. When performing\n",
    "manipulations on a numpy array, the operations are performed immediately.\n",
    "This is not the case for dask arrays. Instead, dask arrays store these\n",
    "operations in a task graph and only evaluate the operations when the user\n",
    "specifies to via a call to a :func:`compute` function. When using\n",
    "nbodykit, often the first task in this graph is loading data from disk.\n",
    "Thus, dask provides nbodykit with on-demand IO functionality, allowing the user\n",
    "to control when data is read from disk.\n",
    "\n",
    "It is useful to describe a bit more about the nuts and bolts of the dask\n",
    "array to illustrate its full power. The dask array object\n",
    "cuts up the full array into many smaller arrays and performs calculations\n",
    "on these smaller \"chunks\". This allows array computations to be\n",
    "performed on large data that does not fit into memory\n",
    "(but can be stored on disk). Particularly useful on laptops and other\n",
    "systems with limited memory, it extends the maximum size of useable datasets\n",
    "from the size of memory to the size of the disk storage. For further details,\n",
    "please see the introduction to the dask array in the\n",
    ":doc:`dask documentation <dask:array-overview>`.\n",
    "\n",
    "By Example\n",
    "----------\n",
    "\n",
    "The dask array functionality is best illustrated by example. Here, we\n",
    "initialize a :class:`~nbodykit.source.catalog.uniform.UniformCatalog`\n",
    "that generates objects with uniformly distributed position and velocity columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nbodykit.lab import UniformCatalog\n",
    "\n",
    "cat = UniformCatalog(nbar=100, BoxSize=1.0, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catalog =  UniformCatalog(size=96, seed=42)\n"
     ]
    }
   ],
   "source": [
    "print(\"catalog = \", cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position =  dask.array<array, shape=(96, 3), dtype=float64, chunksize=(96, 3)> first: [ 0.45470105  0.83263203  0.06905134] last: [ 0.62474599  0.15388738  0.84302209]\n"
     ]
    }
   ],
   "source": [
    "print(\"Position = \", cat['Position'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "We see that the ``Position`` column can be accessed by indexing the catalog\n",
    "with the column name and that the returned object is not a numpy array\n",
    "but a dask array. The dask array has the same ``shape`` (96,3) and\n",
    "``dtype`` ('f8') as the underlying numpy array but also includes the\n",
    "``chunksize`` attribute. This attribute specifies the size of the internal\n",
    "chunks that dask uses to examine arrays in smaller pieces. In this case,\n",
    "the data size is small enough that only a single chunk is needed.\n",
    "\n",
    ".. _dask-array-module:\n",
    "\n",
    "The :mod:`dask.array` module\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "The :mod:`dask.array` module provides much of the same functionality as the\n",
    ":mod:`numpy` module, but with functions optimized to perform operations on\n",
    "dask arrays.\n",
    "\n",
    "For example, we can easily compute the minimum and maximum position coordinates\n",
    "using the :func:`dask.array.min` and :func:`dask.array.max` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum position coordinates =  dask.array<amin-aggregate, shape=(3,), dtype=float64, chunksize=(3,)>\n",
      "maximum position coordinates =  dask.array<amax-aggregate, shape=(3,), dtype=float64, chunksize=(3,)>\n"
     ]
    }
   ],
   "source": [
    "import dask.array as da\n",
    "\n",
    "pos = cat['Position']\n",
    "minpos = da.min(pos, axis=0)\n",
    "maxpos = da.max(pos, axis=0)\n",
    "\n",
    "print(\"minimum position coordinates = \", minpos)\n",
    "print(\"maximum position coordinates = \", maxpos)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Here, we see that the result of our calls to :func:`dask.array.min` and\n",
    ":func:`dask.array.max` are also stored as dask arrays. The task\n",
    "has not yet been performed but instead added to the internal dask task graph.\n",
    "\n",
    "For a full list of the available functionality, please see the\n",
    ":doc:`dask array documentation <dask:array-api>`.\n",
    "A large subset of the most commonly used functions in numpy have\n",
    "implementations in the :mod:`dask.array` module. In addition to these\n",
    "functions, dask arrays support the usual array arithmetic operations. For\n",
    "example, to rescale the position coordinate array, use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BoxSize = 2500.0\n",
    "pos *= BoxSize\n",
    "\n",
    "rescaled_minpos = da.min(pos, axis=0)\n",
    "rescaled_maxpos = da.max(pos, axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _evaluating-dask-array:\n",
    "\n",
    "Evaluating a dask array\n",
    "^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "The :func:`CatalogSource.compute` function computes a dask array and returns\n",
    "the result of the internal series of tasks, either a numpy array or float.\n",
    "For example, we can compute the minimum and maximum of the position coordinates\n",
    "using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum position coordinates =  [ 0.00402579  0.00015685  0.00271747]\n",
      "maximum position coordinates =  [ 0.9927406   0.99610592  0.99925086]\n"
     ]
    }
   ],
   "source": [
    "minpos, maxpos = cat.compute(minpos, maxpos)\n",
    "print(\"minimum position coordinates = \", minpos)\n",
    "print(\"maximum position coordinates = \", maxpos)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "And similarly, we see the result of the rescaling operation earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum re-scaled position coordinates =  [ 10.06446279   0.39212416   6.79367111]\n",
      "maximum re-scaled position coordinates =  [ 2481.85149744  2490.26480949  2498.12715085]\n"
     ]
    }
   ],
   "source": [
    "minpos, maxpos = cat.compute(rescaled_minpos, rescaled_maxpos)\n",
    "print(\"minimum re-scaled position coordinates = \", minpos)\n",
    "print(\"maximum re-scaled position coordinates = \", maxpos)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _caching-with-dask:\n",
    "\n",
    "Caching with Dask\n",
    "-----------------\n",
    "\n",
    "nbodykit automatically caches tasks computed when evaluating dask arrays. The \n",
    "global cache is controlled via the :class:`nbodykit.GlobalCache` class. \n",
    "Often the most expensive task when evaluating a dask array is loading the data\n",
    "from disk. By using dask's caching features, :class:`CatalogSource` objects are\n",
    "able to cache intermediate results, such that repeated calls to\n",
    ":func:`CatalogSource.compute` do not repeat expensive IO operations.\n",
    "\n",
    "The global cache has a fixed size. By default, we set the value to a reasonable\n",
    "(not too large) value. The default value is controlled by the ``global_cache_size``\n",
    "keyword, which can be controlled via the :class:`~nbodykit.set_options` function. \n",
    "Users can control the size of the global cache using:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    from nbodykit import GlobalCache\n",
    "    GlobalCache.resize(2e9) # set cache size to 2 GB \n",
    "\n",
    "\n",
    ".. note::\n",
    "\n",
    "    When accessing columns of a :class:`CatalogSource`, the returned dask \n",
    "    array also has a :func:`compute` function. When using this function to \n",
    "    evaluate dask arrays, internal caching will also be used. So users have the \n",
    "    option of using :func:`CatalogSource.compute` or the :func:`compute` \n",
    "    attached to each dask array. \n",
    " \n",
    ".. _larger-than-memory-arrays:\n",
    "\n",
    "Examining Larger-than-Memory Data\n",
    "---------------------------------\n",
    "\n",
    ":class:`CatalogSource` objects automatically take advantage of the chunking\n",
    "features of the dask array, greatly reducing the difficulties of\n",
    "analyzing larger-than-memory data. When combined with the ability of the\n",
    ":class:`CatalogSource` object to provide a continuous view of multiple files\n",
    "at once, we can analyze large amounts of data from a single catalog with ease.\n",
    "\n",
    "A common use case is examining a directory of large binary outputs from a\n",
    "N-body simulation on a laptop. Often the user wishes to select a smaller subsample\n",
    "of the catalog or perform some trivial data inspection to verify the accuracy of\n",
    "the data. These tasks become straightforward with nbodykit, using the functionality\n",
    "provided by the :class:`CatalogSource` object and the :mod:`dask` package.\n",
    "Regardless of the size of the data that the user is loading, the nbodykit\n",
    ":class:`CatalogSource` interface remains the same."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

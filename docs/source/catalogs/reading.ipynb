{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# this cell is hidden\n",
    "import tempfile, os\n",
    "startdir = os.path.abspath('.')\n",
    "tmpdir = tempfile.mkdtemp()\n",
    "os.chdir(tmpdir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. currentmodule:: nbodykit.source.catalog\n",
    "\n",
    ".. _reading-catalogs:\n",
    "\n",
    "Reading Catalogs from Disk\n",
    "==========================\n",
    "\n",
    "Supported Data Formats\n",
    "----------------------\n",
    "\n",
    "nbodykit provides support for initializing\n",
    ":class:`~nbodykit.base.catalog.CatalogSource` objects by reading tabular data\n",
    "stored on disk in a variety of formats:\n",
    "\n",
    "* :ref:`csv-data`\n",
    "* :ref:`binary-data`\n",
    "* :ref:`hdf-data`\n",
    "* :ref:`bigfile-data`\n",
    "* :ref:`fits-data`\n",
    "\n",
    "In this section, we provide short examples illustrating how to read data\n",
    "stored in each of these formats. If your data format is not currently\n",
    "supported, please see :ref:`custom-data-format`.\n",
    "\n",
    ".. _csv-data:\n",
    "\n",
    "Plaintext Data\n",
    "^^^^^^^^^^^^^^\n",
    "\n",
    "Reading data stored as columns in plaintext files is supported via the\n",
    ":class:`~file.CSVCatalog` class. This class partitions the CSV file into chunks, and\n",
    "data is only read from the relevant chunks of the file, using\n",
    "the :func:`pandas.read_csv` function. The class accepts any configuration\n",
    "keywords that this function does. The partitioning step provides a significant\n",
    "speed-up when reading from the end of the file, since the entirety of the data\n",
    "does not need to be read first.\n",
    "\n",
    "**Caveats**\n",
    "\n",
    "- By default, the class reads space-separated columns, but this can be\n",
    "  changed by setting ``delim_whitespace=False`` and changing the ``delimiter``\n",
    "  keyword\n",
    "- A :mod:`pandas` index column is not supported -- all columns should represent\n",
    "  data columns to read.\n",
    "- Commented lines in the file are not supported -- please remove all comments\n",
    "  from the file before loading into nbodykit.\n",
    "- There should not be a header line in the file -- column names should be passed\n",
    "  to :class:`~file.CSVCatalog` via the ``names`` argument.\n",
    "\n",
    "As an example, below we generate 5 columns for 100 fake objects and write\n",
    "to a plaintext file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVCatalog(size=100, file='csv-example.txt')\n",
      "columns =  ['Selection', 'Value', 'Weight', 'a', 'b', 'c', 'd', 'e']\n",
      "total size =  100\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from nbodykit.source.catalog import CSVCatalog\n",
    "\n",
    "# generate some fake ASCII data\n",
    "data = numpy.random.random(size=(100,5))\n",
    "\n",
    "# save to a plaintext file\n",
    "numpy.savetxt('csv-example.txt', data, fmt='%.7e')\n",
    "\n",
    "# name each of the 5 input columns\n",
    "names =['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "# read the data\n",
    "f = CSVCatalog('csv-example.txt', names)\n",
    "\n",
    "print(f)\n",
    "print(\"columns = \", f.columns) # default Weight,Selection also present\n",
    "print(\"total size = \", f.csize)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _binary-data:\n",
    "\n",
    "Binary Data\n",
    "^^^^^^^^^^^\n",
    "\n",
    "The :class:`~file.BinaryCatalog` object reads binary data that is stored\n",
    "on disk in a column-major format. The class can read any numpy data type\n",
    "and can handle arbitrary byte offsets between columns.\n",
    "\n",
    "**Caveats**\n",
    "\n",
    "- Columns must be stored in consecutive order in the binary file\n",
    "  (column-major format).\n",
    "\n",
    "For example, below we save ``Position`` and ``Velocity`` columns to a binary\n",
    "file and load them into a :class:`~file.BinaryCatalog`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryCatalog(size=1024, file='binary-example.dat')\n",
      "columns =  ['Position', 'Selection', 'Value', 'Velocity', 'Weight']\n",
      "total size =  1024\n"
     ]
    }
   ],
   "source": [
    "from nbodykit.source.catalog import BinaryCatalog\n",
    "\n",
    "# generate some fake data and save to a binary file\n",
    "with open('binary-example.dat', 'wb') as ff:\n",
    "    pos = numpy.random.random(size=(1024, 3)) # fake Position column\n",
    "    vel = numpy.random.random(size=(1024, 3)) # fake Velocity column\n",
    "    pos.tofile(ff); vel.tofile(ff); ff.seek(0)\n",
    "\n",
    "# create the binary catalog\n",
    "f = BinaryCatalog(ff.name, [('Position', ('f8', 3)), ('Velocity', ('f8', 3))], size=1024)\n",
    "\n",
    "print(f)\n",
    "print(\"columns = \", f.columns) # default Weight,Selection also present\n",
    "print(\"total size = \", f.csize)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _hdf-data:\n",
    "\n",
    "HDF Data\n",
    "^^^^^^^^\n",
    "\n",
    "The :class:`~file.HDFCatalog` object uses the :mod:`h5py` module to read\n",
    "HDF5 files. The class supports reading columns stored in :class:`h5py.Dataset`\n",
    "objects and in :class:`h5py.Group` objects, assuming that all arrays are of the\n",
    "same length since catalog objects must have a fixed size. Columns stored in\n",
    "different datasets or groups can be accessed via their full path in the\n",
    "HDF5 file.\n",
    "\n",
    "**Caveats**\n",
    "\n",
    "- :class:`~file.HDFCatalog` attempts to load all possible datasets or groups\n",
    "  from the HDF5 file. This can present problems if the data has different lengths.\n",
    "  Use the ``exclude`` keyword to explicitly exclude data that has the wrong\n",
    "  size.\n",
    "\n",
    "In the example below, we load fake data from both the dataset \"Data1\" and\n",
    "from the group \"Data2\" in an example HDF5 file. \"Data1\" is a single structured\n",
    "numpy array with ``Position`` and ``Velocity`` columns, while \"Data2\" is a\n",
    "group storing the ``Position`` and ``Velocity`` columns separately. nbodykit\n",
    "is able to load both types of data from HDF5 files, and the corresponding\n",
    "column names are the full paths of the data in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDFCatalog(size=1024, file='hdf-example.hdf5')\n",
      "columns =  ['Data1/Mass', 'Data1/Position', 'Data2/Mass', 'Data2/Position', 'Selection', 'Value', 'Weight']\n",
      "total size =  1024\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from nbodykit.source.catalog import HDFCatalog\n",
    "\n",
    "# generate some fake data\n",
    "dset = numpy.empty(1024, dtype=[('Position', ('f8', 3)), ('Mass', 'f8')])\n",
    "dset['Position'] = numpy.random.random(size=(1024, 3))\n",
    "dset['Mass'] = numpy.random.random(size=1024)\n",
    "\n",
    "# write to a HDF5 file\n",
    "with h5py.File('hdf-example.hdf5' , 'w') as ff:\n",
    "    ff.create_dataset('Data1', data=dset)\n",
    "    grp = ff.create_group('Data2')\n",
    "    grp.create_dataset('Position', data=dset['Position']) # column as dataset\n",
    "    grp.create_dataset('Mass', data=dset['Mass']) # column as dataset\n",
    "\n",
    "# intitialize the catalog\n",
    "f = HDFCatalog('hdf-example.hdf5')\n",
    "\n",
    "print(f)\n",
    "print(\"columns = \", f.columns) # default Weight,Selection also present\n",
    "print(\"total size = \", f.csize)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _bigfile-data:\n",
    "\n",
    "Bigfile Data\n",
    "^^^^^^^^^^^^\n",
    "\n",
    "The `bigfile <https://github.com/rainwoodman/bigfile>`_ package is a massively\n",
    "parallel IO library for large, hierarchical datasets, and nbodykit supports\n",
    "reading data stored in this format using :class:`~file.BigFileCatalog`.\n",
    "\n",
    "**Caveats**\n",
    "\n",
    "- Similiar to the :class:`~file.HDFCatalog` class, datasets of the wrong size\n",
    "  stored in a bigfile format should be explicitly excluded using the\n",
    "  ``exclude`` keyword.\n",
    "\n",
    "Below, we load ``Position`` and ``Velocity`` columns, stored in the\n",
    ":mod:`bigfile` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigFileCatalog(size=512, file='bigfile-example')\n",
      "columns =  ['Position', 'Selection', 'Value', 'Velocity', 'Weight']\n",
      "total size =  512\n"
     ]
    }
   ],
   "source": [
    "import bigfile\n",
    "from nbodykit.source.catalog import BigFileCatalog\n",
    "\n",
    "# generate some fake data\n",
    "data = numpy.empty(512, dtype=[('Position', ('f8', 3)), ('Velocity', ('f8',3))])\n",
    "data['Position'] = numpy.random.random(size=(512, 3))\n",
    "data['Velocity'] = numpy.random.random(size=(512,3))\n",
    "\n",
    "# save fake data to a BigFile\n",
    "with bigfile.BigFile('bigfile-example', create=True) as tmpff:\n",
    "    with tmpff.create(\"Position\", dtype=('f4', 3), size=512) as bb:\n",
    "        bb.write(0, data['Position'])\n",
    "    with tmpff.create(\"Velocity\", dtype=('f4', 3), size=512) as bb:\n",
    "        bb.write(0, data['Velocity'])\n",
    "    with tmpff.create(\"Header\") as bb:\n",
    "        bb.attrs['Size'] = 512.\n",
    "\n",
    "# initialize the catalog\n",
    "f = BigFileCatalog('bigfile-example', header='Header')\n",
    "\n",
    "print(f)\n",
    "print(\"columns = \", f.columns) # default Weight,Selection also present\n",
    "print(\"total size = \", f.csize)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _fits-data:\n",
    "\n",
    "FITS Data\n",
    "^^^^^^^^^\n",
    "\n",
    "The `FITS <https://fits.gsfc.nasa.gov>`_ data format is supported via the\n",
    ":class:`~file.FITSCatalog` object. nbodykit relies on the\n",
    "`fitsio <https://github.com/esheldon/fitsio>`_ package to perform the read\n",
    "operation.\n",
    "\n",
    "**Caveats**\n",
    "\n",
    "- The FITS file must contain a readable binary table of data.\n",
    "- Specific extensions to read can be passed via the ``ext`` keyword. By default,\n",
    "  data is read from the first HDU that has readable data.\n",
    "\n",
    "For example, below we load ``Position`` and ``Velocity`` data from a FITS file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FITSCatalog(size=1024, file='fits-example.fits')\n",
      "columns =  ['Mass', 'Position', 'Selection', 'Value', 'Weight']\n",
      "total size =  1024\n"
     ]
    }
   ],
   "source": [
    "import fitsio\n",
    "from nbodykit.source.catalog import FITSCatalog\n",
    "\n",
    "# generate some fake data\n",
    "dset = numpy.empty(1024, dtype=[('Position', ('f8', 3)), ('Mass', 'f8')])\n",
    "dset['Position'] = numpy.random.random(size=(1024, 3))\n",
    "dset['Mass'] = numpy.random.random(size=1024)\n",
    "\n",
    "# write to a FITS file using fitsio\n",
    "fitsio.write('fits-example.fits', dset, extname='Data')\n",
    "\n",
    "# initialize the catalog\n",
    "f = FITSCatalog('fits-example.fits', ext='Data')\n",
    "\n",
    "print(f)\n",
    "print(\"columns = \", f.columns) # default Weight,Selection also present\n",
    "print(\"total size = \", f.csize)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _reading-multiple-files:\n",
    "\n",
    "Reading Multiple Data Files at Once\n",
    "-----------------------------------\n",
    "\n",
    ":class:`~nbodykit.base.catalog.CatalogSource` objects support reading\n",
    "multiple files at once, providing a continuous view of each individual catalog\n",
    "stacked together. Each file read must contain the same data types, otherwise\n",
    "the data cannot be combined into a single catalog.\n",
    "\n",
    "This becomes particularly useful when the user has data\n",
    "split into multiple files in a single directory, as is often the case when\n",
    "processing large amounts of data. For example, output binary snapshots from\n",
    "N-body simulations, often totaling 10GB - 100GB in size, can be read into a\n",
    "single :class:`~file.BinaryCatalog` with nbodykit.\n",
    "\n",
    "When specifying multiple files to load, the user can use either an explicit\n",
    "list of file names or use an asterisk glob pattern to match files.\n",
    "As an example, below, we read data from two plaintext files into a single\n",
    ":class:`~file.CSVCatalog`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "data = numpy.random.random(size=(100,5))\n",
    "\n",
    "# save first 40 rows of data to file\n",
    "numpy.savetxt('csv-example-1.txt', data[:40], fmt='%.7e')\n",
    "\n",
    "# save the remaining 60 rows to another file\n",
    "numpy.savetxt('csv-example-2.txt', data[40:], fmt='%.7e')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Using a glob pattern\n",
    "^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVCatalog(size=100, file='csv-example-*')\n",
      "total size =  100\n"
     ]
    }
   ],
   "source": [
    "# the names of the columns in both files\n",
    "names =['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "# read with a glob pattern\n",
    "f = CSVCatalog('csv-example-*', names)\n",
    "\n",
    "print(f)\n",
    "\n",
    "# combined catalog size is 40+60=100\n",
    "print(\"total size = \", f.csize)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Using a list of file names\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVCatalog(size=100, nfiles=2)\n",
      "total size =  100\n"
     ]
    }
   ],
   "source": [
    "# the names of the columns in both files\n",
    "names =['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "# read with a list of the file names\n",
    "f = CSVCatalog(['csv-example-1.txt', 'csv-example-2.txt'], names)\n",
    "\n",
    "print(f)\n",
    "\n",
    "# combined catalog size is 40+60=100\n",
    "print(\"total size = \", f.csize)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _custom-data-format:\n",
    "\n",
    "Reading a Custom Data Format\n",
    "----------------------------\n",
    "\n",
    ".. currentmodule:: nbodykit.io\n",
    "\n",
    "Users can implement their own subclasses of :class:`CatalogSource` for reading\n",
    "custom data formats with a few easy steps. The core functionality of the\n",
    ":class:`CatalogSource` classes described in this section use the\n",
    ":mod:`nbodykit.io` module for reading data from disk. This module implements the\n",
    ":class:`nbodykit.io.base.FileType` base class, which is an abstract\n",
    "class that behaves like a :obj:`file`-like object. For the built-in\n",
    "file formats discussed in this section, we have implemented the following\n",
    "subclasses of :class:`~nbodykit.io.base.FileType` in the :mod:`nbodykit.io`\n",
    "module: :class:`~csv.CSVFile`, :class:`~binary.BinaryFile`,\n",
    ":class:`~bigfile.BigFile`, :class:`~hdf.HDFFile`, and :class:`~fits.FITSFile`.\n",
    "\n",
    "To make a valid subclass of :class:`~nbodykit.io.base.FileType`, users must:\n",
    "\n",
    "#. Implement the :func:`~nbodykit.io.base.FileType.read` function that reads\n",
    "   a range of the data from disk.\n",
    "#. Set the :attr:`size` in the :func:`__init__` function, specifying the total\n",
    "   size of the data on disk.\n",
    "#. Set the :attr:`dtype` in the :func:`__init__` function, specifying the type\n",
    "   of data stored on disk.\n",
    "\n",
    "Once we have the custom subclass implemented, the\n",
    ":func:`nbodykit.source.catalog.file.FileCatalogFactory` function can\n",
    "be used to automatically create a custom :class:`CatalogSource` object\n",
    "from the subclass.\n",
    "\n",
    "As a toy example, we will illustrate how this is done for data saved\n",
    "using the numpy ``.npy`` format. First, we will implement our\n",
    "subclass of the :class:`~nbodykit.io.base.FileType` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nbodykit.io.base import FileType\n",
    "\n",
    "class NPYFile(FileType):\n",
    "    \"\"\"\n",
    "    A file-like object to read numpy ``.npy`` files\n",
    "    \"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.attrs = {}\n",
    "        # load the data and set size and dtype\n",
    "        self._data = numpy.load(self.path)\n",
    "        self.size = len(self._data) # total size\n",
    "        self.dtype = self._data.dtype # data dtype\n",
    "        \n",
    "    def read(self, columns, start, stop, step=1):\n",
    "        \"\"\"\n",
    "        Read the specified column(s) over the given range\n",
    "        \"\"\"\n",
    "        return self._data[start:stop:step]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "And now generate the subclass of :class:`CatalogSource`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nbodykit.source.catalog.file import FileCatalogFactory\n",
    "\n",
    "NPYCatalog = FileCatalogFactory('NPYCatalog', NPYFile)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "And finally, we generate some fake data, save it to a ``.npy`` file,\n",
    "and then load it with our new ``NPYCatalog`` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPYCatalog(size=1024, file='npy-example.npy')\n",
      "columns =  ['Mass', 'Position', 'Selection', 'Value', 'Weight']\n",
      "total size =  1024\n"
     ]
    }
   ],
   "source": [
    "# generate the fake data\n",
    "data = numpy.empty(1024, dtype=[('Position', ('f8', 3)), ('Mass', 'f8')])\n",
    "data['Position'] = numpy.random.random(size=(1024, 3))\n",
    "data['Mass'] = numpy.random.random(size=1024)\n",
    "\n",
    "# save to a npy file\n",
    "numpy.save(\"npy-example.npy\", data)\n",
    "\n",
    "# and now load the data\n",
    "f = NPYCatalog(\"npy-example.npy\")\n",
    "\n",
    "print(f)\n",
    "print(\"columns = \", f.columns) # default Weight,Selection also present\n",
    "print(\"total size = \", f.csize)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "This toy example illustrates how custom data formats can be incorporated\n",
    "into nbodykit, but users should take care to optimize their storage\n",
    "solutions for more complex applications. In particular, data storage formats\n",
    "that are stored in column-major format and allow data slices from arbitrary\n",
    "locations to be read should be favored. This enables large speed-ups when\n",
    "reading data in parallel. On the contrary, our simple toy example class\n",
    ":class:`NPYFile` reads the entirety of the data before returning\n",
    "a certain slice in the :func:`read` function. In general, this should be\n",
    "avoided if at all possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "os.chdir(startdir)\n",
    "shutil.rmtree(tmpdir)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
